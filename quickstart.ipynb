{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "import faiss\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.cm as cm\n",
    "import commons\n",
    "import network\n",
    "import sys\n",
    "from Parser import Parser\n",
    "from collections import OrderedDict\n",
    "\n",
    "import network\n",
    "import utils\n",
    "import datasets_dual\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "parser = Parser()\n",
    "sys.argv = ['a'] # 非常神奇，居然可直接这样模拟\n",
    "args = parser.parse_arguments()\n",
    "args.device = 'cuda'\n",
    "print(args)\n",
    "\n",
    "features_dim = 768\n",
    "save_path = 'path/to/your/save/directory'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network.RGBTVPRNet(forward_fn = args.fuse_fn, pretrained_foundation = True, foundation_model_path = '/path/to/your/pretrained/weights')\n",
    "\n",
    "model = model.to('cuda')\n",
    "\n",
    "model = utils.resume_model('/path/to/your/checkpoint', model)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = faiss.StandardGpuResources()\n",
    "faiss_index_cpu = faiss.IndexFlatL2(features_dim)\n",
    "\n",
    "DATASET_FOLDER = \"/path/to/your/dataset\"\n",
    "args.img_time = 'allday'\n",
    "args.sequences = ['SNU']\n",
    "args.soft_positives_dist_threshold = 10\n",
    "\n",
    "test_ds = datasets_dual.BaseSTheReODual(args, DATASET_FOLDER, split='test')\n",
    "print(f\"database: {test_ds.database_num}, queries: {test_ds.queries_num}\")\n",
    "\n",
    "db_ds = Subset(test_ds, list(range(test_ds.database_num)))\n",
    "q_ds = Subset(test_ds, list(range(test_ds.database_num, len(test_ds))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute database features\n",
    "\n",
    "database_dataloader = DataLoader(dataset=db_ds, num_workers=71,\n",
    "                                        batch_size=196, pin_memory=True,\n",
    "                                        shuffle=False)\n",
    "# print(features_dim)\n",
    "database_features = np.empty((test_ds.database_num, features_dim), dtype=\"float32\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, indices in tqdm(database_dataloader):\n",
    "        features = model(inputs.to('cuda')).view(-1, features_dim)\n",
    "        features = features.cpu().numpy()\n",
    "        # print(features.shape)\n",
    "        database_features[indices.numpy(), :] = features\n",
    "\n",
    "    # faiss_index = faiss.index_cpu_to_gpu(res, 0, faiss_index_cpu)\n",
    "    faiss_index = faiss_index_cpu\n",
    "    faiss_index.add(database_features)\n",
    "    # del database_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute query feature\n",
    "\n",
    "query_index = 420   # specify the query index\n",
    "\n",
    "with torch.no_grad():\n",
    "    query, _ = q_ds[query_index]\n",
    "    query = query.unsqueeze(0)\n",
    "    query_feature = model(query.to('cuda')).cpu().numpy()\n",
    "    \n",
    "    positives_nums = 20 # retrieve 20 database samples\n",
    "    distances, predictions = faiss_index.search(query_feature, positives_nums)\n",
    "\n",
    "\n",
    "positives_indexes = test_ds.get_positives()[query_index]\n",
    "\n",
    "print(f\"positives: {positives_indexes}\")\n",
    "print(f\"predictions: {predictions}\")\n",
    "\n",
    "if predictions[0][0] in positives_indexes:\n",
    "    print(\"hit\")\n",
    "else:\n",
    "    print(\"miss\")\n",
    "\n",
    "# find false positives\n",
    "false_positives = []\n",
    "for index in predictions[0]:\n",
    "    if index not in positives_indexes:\n",
    "        false_positives.append(index)\n",
    "\n",
    "# save results\n",
    "database_num = test_ds.database_num\n",
    "query_rgb_path = test_ds.rgb_img_paths[query_index+database_num]\n",
    "query_t_path = test_ds.t_img_paths[query_index+database_num]\n",
    "query_pose = test_ds.queries_utms[query_index]\n",
    "\n",
    "neighbors = []\n",
    "for neighbor_index in predictions[0]:\n",
    "    assert neighbor_index < database_num\n",
    "    neighbor_rgb_path = test_ds.rgb_img_paths[neighbor_index]\n",
    "    neighbor_t_path = test_ds.t_img_paths[neighbor_index]\n",
    "    neighbor_pose = test_ds.database_utms[neighbor_index]\n",
    "\n",
    "    neighbors.append({\n",
    "        \"rgb_path\": neighbor_rgb_path,\n",
    "        \"t_path\": neighbor_t_path,\n",
    "        \"pose\": neighbor_pose\n",
    "    })\n",
    "\n",
    "results = {\n",
    "            \"query\": {\n",
    "                \"rgb_path\": query_rgb_path,\n",
    "                \"t_path\": query_t_path,\n",
    "                \"pose\": query_pose\n",
    "            },\n",
    "            \"neighbors\": neighbors\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the retrieved image pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rgb_img(path):\n",
    "    rgb_image = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    rgb_image = cv2.cvtColor(rgb_image, cv2.COLOR_BAYER_BG2RGB)\n",
    "    # rgb_image = cv2.cvtColor(rgb_image, cv2.COLOR_BAYER_RG2RGB)\n",
    "    \n",
    "    return rgb_image\n",
    "\n",
    "def read_t_img(path):\n",
    "    t_img = cv2.imread(path, cv2.IMREAD_ANYDEPTH)\n",
    "    t_img = cv2.normalize(t_img, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    t_img = cv2.cvtColor(t_img, cv2.COLOR_GRAY2RGB)\n",
    "    return t_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the retrieved image pairs\n",
    "k = 5\n",
    "\n",
    "fig, axes = plt.subplots(2, k + 1, figsize=(15, 5))\n",
    "fig.suptitle(f\"Query-{query_index} and Top-{k} Predictions\", fontsize=24)\n",
    "plt.subplots_adjust(top=0.5)\n",
    "for ax in axes.flatten():\n",
    "    ax.axis(\"off\")\n",
    "plt.subplots_adjust(hspace=-1.18)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# show query image\n",
    "query_rgb_img = read_rgb_img(results[\"query\"][\"rgb_path\"])\n",
    "query_t_img = read_t_img(results[\"query\"][\"t_path\"])\n",
    "axes[0, 0].imshow(query_rgb_img)\n",
    "axes[0, 0].set_title(\"Query\")\n",
    "axes[1, 0].imshow(query_t_img)\n",
    "# save query image\n",
    "os.makedirs(f\"{save_path}/q_{query_index}\", exist_ok=True)\n",
    "cv2.imwrite(f\"{save_path}/q_{query_index}/q_rgb.png\", query_rgb_img)\n",
    "cv2.imwrite(f\"{save_path}/q_{query_index}/q_t.png\", query_t_img)\n",
    "\n",
    "# show retrieved images\n",
    "for i, neighbor in enumerate(results[\"neighbors\"][:k]):\n",
    "    rgb_img = read_rgb_img(neighbor[\"rgb_path\"])\n",
    "    t_img = read_t_img(neighbor[\"t_path\"])\n",
    "    axes[0, i + 1].imshow(rgb_img)\n",
    "    axes[0, i + 1].set_title(f\"predicitons {i + 1}\")\n",
    "    axes[1, i + 1].imshow(t_img)\n",
    "    # save retrieved images\n",
    "    cv2.imwrite(f\"{save_path}/q_{query_index}/pr_{i + 1}_rgb.png\", rgb_img)\n",
    "    cv2.imwrite(f\"{save_path}/q_{query_index}/pr_{i + 1}_t.png\", t_img)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
